from __future__ import print_function
from bokeh.plotting import figure, show, output_file
from bokeh.models import ColumnDataSource, LabelSet, HoverTool
import argparse
import numpy as np
from numpy.linalg import cholesky
from bokeh.transform import linear_cmap
from bokeh.palettes import RdYlGn10
from numpy.linalg import norm
from MulticoreTSNE import MulticoreTSNE as TSNE

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
from matplotlib.ticker import NullFormatter
from sklearn import manifold, datasets

vec = "model_sentence_score.vec"
perplexity = 45
K = 25031
step = 8
n_components = 2

# parser = argparse.ArgumentParser()
# parser.add_argument('-vec', action='store', dest='vectorfile', required=True,
#                     help='Path of model.vec generated by fasttext')
# parser.add_argument('-p', action='store', type=int, dest='perplexity',
#                     default=20, help='Perplexity, usually between 20 to 50')
# parser.add_argument('-topK', action='store', type=int, dest='topK',
#                     default=500, help='show topK words with largest embedding norm')

def load_data(vectorfile, topK, step):
    words = []
    with open(vectorfile) as fin:
        next(fin)  # skip first line containing word_num and embedding_dim
        for line in fin:
            line = line.strip('\n').split()
            words.append((line[0], line[1:]))
    print('Loaded {} words, embedding dim = {}'.format(len(words), len(words[0][1])))
    words = sorted(words, key=lambda x: norm(x[1]), reverse=True)
    # words_sorted_by_score = sorted(words, key=lambda x: x[0], reverse=True)

    labels, embeddings = [], []
    count = 0
    for word in words[:topK]:
        if count % step == 0:
            labels.append(word[0])
            embeddings.append(np.array(word[1]))
        count += 1
    return labels, np.array(embeddings)


def plot_embedding():
    print('Loading data...')
    words, embeddings = load_data(vec, K, step)
    words = list(map(float, words))
    # print(words)
    tsne = TSNE(n_components=n_components, n_jobs=4, perplexity=perplexity, verbose=1)
    Y = tsne.fit_transform(embeddings)
    source = ColumnDataSource(data=dict(x=Y[:, 0], y=Y[:, 1], words=words))
    hover = HoverTool(tooltips=[("word", "@words")])

    tools = ['pan', 'wheel_zoom', 'reset', hover]
    p = figure(title='t-SNE embedding of top ' + str(len(Y)) + ' words', plot_width=1200, plot_height=720, tools=tools)
    mapper = linear_cmap(field_name='words', palette=RdYlGn10, low=max(words), high=min(words))
    p.scatter(x='x', y='y', size=8, source=source, color=mapper)
    labels = LabelSet(x='x', y='y', text='words', level='glyph', x_offset=5, y_offset=5, source=source,
                      render_mode='canvas')
    p.add_layout(labels)
    show(p)

    # _, color = datasets.samples_generator.make_s_curve(K, random_state=0)
    # fig = plt.figure(figsize=(8, 8))
    # ax = fig.add_subplot(2, 1, 2)
    # ax.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)
    # # ax.view_init(4, -72)
    # plt.show()

    # n_neighbors = 10
    # X, color = datasets.samples_generator.make_s_curve(K, random_state=0)
    # fig = plt.figure(figsize=(8, 8))
    # ax = fig.add_subplot(211, projection='3d')
    # ax.scatter(X[:, 0], X[:, 1], X[:, 2], c=color, cmap=plt.cm.Spectral)
    # ax.view_init(4, -72)
    # # 创建了一个figure，标题为"Manifold Learning with 1000 points, 10 neighbors"
    # plt.suptitle("Manifold Learning with %i points, %i neighbors"
    #              % (1000, n_neighbors), fontsize=14)
    # ax = fig.add_subplot(2, 1, 2)
    # plt.scatter(Y[:, 0], Y[:, 1], c=color, cmap=plt.cm.Spectral)
    # ax.xaxis.set_major_formatter(NullFormatter())  # 设置标签显示格式为空
    # ax.yaxis.set_major_formatter(NullFormatter())
    # plt.axis('tight')

    # plt.show()


plot_embedding()
